<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Yun Chung and Sebastian Mejia </div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-la-celeste-website">cal-cs184-student.github.io/hw-webpages-la-celeste-website</a>
		<br>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-fiat-lux">github.com/cal-cs184-student/sp25-hw3-fiat-lux</a>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		<p>
		  <b>
		    Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.
		  </b>
		</p>

		<h2>Part 1: Ray Generation and Scene Intersection</h2>

		<p>
		  <b>
		    Walk through the ray generation and primitive intersection parts of the rendering pipeline.
		  </b>
		</p>

		<p>
		  We implemented raytracing with a for loop that iterates over the number of random samples (ns_aa) of some pixel (x, y) in the image.
		  After we normalize the x and y values over the image's dimensions, we compute the radiance of each sampled ray. We then get the sum of radiances
		  and divide it by the number of samples to get the average estimated radiance, which is then written to the sample buffer after updating the pixel
		  with the average radiance color.
		</p>

		<p>
		  <b>
		    Explain the triangle intersection algorithm you implemented in your own words.
		  </b>
		</p>

		<p>
		  The triangle intersection algorithm was pretty much based off the Möller-Trumbore Algorithm as described in Lecture 9-10, slide 21.
		  If the ray's direction is parallel to the triangle, there is no intersection (S1 * E1 == 0).
		  We calculate Barycentric coordinates as shown in the diagram from lecture, and use those along with r.min_t and r.max_t to test for intersection.
		</p>

		<figure>
	        <img
	          src="./images/Möller-Trumbore.png"
	          style="width: 50%"
	          />
	        </figure>

		<p>
		  <b>
		    Show images with normal shading for a few small .dae files.
		  </b>
		</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="images/CBempty.png" width="400px"/>
				  <figcaption>Room rendering.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="images/CBspheres.png" width="400px"/>
				  <figcaption>Room with spheres rendering.</figcaption>
				</td>
			  </tr>
			</table>
		</div>.

		<h2>Part 2: Bounding Volume Hierarchy</h2>
			
		<p>
		  <b>
		    Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
		  </b>
		</p>

		<p>
		  Our BVH construction algorithm constructs a binary tree where each node has a bounding box, which we expanded as necessary.
		  If the current node has less than <code>max_leaf_size</code> primitives, then it's a leaf node. We give it iterators to the start and end of its primitives, and return.
		  Afterwards, we handle the internal node case. We select the splitting axis based on the bounding box's largest dimension.
		  Our splitting heuristic is a median split; we divide primitives in half with <code>midpoint = start + (n / 2)</code>. This ensures that the tree is balanced.
		</p>

		<p>
		  <b>
		    Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
		  </b>
		</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
		  <table style="width: 100%; text-align: center; border-collapse: collapse;">
		    <tr>
		      <td style="text-align: center;">
	                <img src="images/wall-e.png" width="400px"/>
			<figcaption>"Eva ❤️"</figcaption>
		      </td>
		      <td style="text-align: center;">
		        <img src="images/dragon.png" width="400px"/>
		        <figcaption>"Rawr"</figcaption>
		      </td>
		    </tr>
		  </table>
		</div>

		<p>
		  <b>
		    Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
		  </b>
		</p>

		<p>
		  As you can see in the images below, implementing BVH substantially sped up the rendering runtime. It appears that the BVH implementation spends SLIGHTLY more time
		  on collecting primitives and building the BVH (since this isn't relevant to the non-BVH implementation). The BVH implementation took roughly 1/100th of the time
		  to render, its average speed was roughly 100 times faster, and it averaged roughly 100 times less intersection tests per ray.
		</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
		  <table style="width: 100%; text-align: center; border-collapse: collapse;">
		    <tr>
		      <td style="text-align: center;">
	                <img src="images/before_bvh.png" width="400px"/>
			<figcaption>Stats before BVH.</figcaption>
		      </td>
		      <td style="text-align: center;">
		        <img src="images/after_bvh.png" width="400px"/>
		        <figcaption>Stats after BVH.</figcaption>
		      </td>
		    </tr>
		  </table>
		</div>.

		<h2>Part 3: Direct Illumination</h2>

		<p>
		  <b>
		    Walk through both implementations of the direct lighting function.
		  </b>
		</p>

		<p>
		  <b>
		    Show some images rendered with both implementations of the direct lighting function.
		  </b>
		</p>

		<p>
		  <b>
		    Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
		  </b>
		</p>

		<p>
		  <b>
		    Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
		  </b>
		</p>

		<h2>Part 4: Global Illumination</h2>
		
		<p>
		  <b>
		    Walk through your implementation of the indirect lighting function.
		  </b>
		</p>

		<p>
		  <b>
		    Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
		  </b>
		</p>

		<p>
		  <b>
		    Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
		  </b>
		</p>

		<p>
		  <b>
		    For CBbunny.dae, render the mth bounce of light with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag), and isAccumBounces=false. Explain in your write-up what you see for the 2nd and 3rd bounce of light, and how it contributes to the quality of the rendered image compared to rasterization. Use 1024 samples per pixel.
		    <ul>
		      <li>
		        Compare rendered views of accumulated and unaccumulated bounces for CBbunny.dae with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag). Use 1024 samples per pixel.
		      </li>
		    </ul>
		  </b>
		</p>

		<p>
		  <b>
		    For CBbunny.dae, output the Russian Roulette rendering with max_ray_depth set to 0, 1, 2, 3, 4, and 100(the -m flag). Use 1024 samples per pixel.
		  </b>
		</p>

		<p>
		  <b>
		    Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
		  </b>
		</p>

		<p>
		  <b>
		    You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours.
		  </b>
		</p>

		<h2>Part 5: Adaptive Sampling</h2>

		<p>
		  <b>
		    Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
		  </b>
		</p>

		<p>
		  <b>
		    Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
		  </b>
		</p>

		<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
		
		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>
